{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собрание annotations см в YOLO_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_dataset_path = 'YOLO_DATASET_ANNOTATIONS/'\n",
    "\n",
    "train_annotation_path = os.path.join(yolo_dataset_path, '_train_annotations.txt')\n",
    "validate_annotation_path = os.path.join(yolo_dataset_path, '_validate_annotations.txt')\n",
    "test_annotation_path = os.path.join(yolo_dataset_path, '_test_annotations.txt')\n",
    "\n",
    "classes_path = 'YOLO_DATASET_ANNOTATIONS/_classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_annotation_path, 'r') as f:\n",
    "    train_lines = list(map(lambda x: '../dataset/map/' + x.strip() , f.readlines()))\n",
    "\n",
    "with open(validate_annotation_path, 'r') as f:\n",
    "    validate_lines = list(map(lambda x: '../dataset/map/' + x.strip() , f.readlines()))\n",
    "    \n",
    "with open(test_annotation_path, 'r') as f:\n",
    "    test_lines = list(map(lambda x: '../dataset/map/' + x.strip() , f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dataset/map/6646.png 190,93,196,98,1 109,155,115,163,0 278,156,284,164,0 278,249,284,257,3 9,17,15,25,3 156,315,162,323,3 287,214,293,222,3 293,202,299,210,3 215,100,221,108,3 48,51,54,59,3 77,112,83,120,3 103,92,109,100,3 279,178,285,186,3 262,255,268,263,3 207,182,213,190,3 7,93,13,101,3 60,89,66,97,3 207,219,213,227,3 235,93,241,101,3 86,88,92,96,3 266,279,272,287,3 71,86,77,94,3 162,23,168,31,3 242,133,248,141,3 12,57,18,65,3 65,69,71,77,3 286,65,292,73,3 22,38,28,46,3 180,72,186,80,3 284,32,290,40,3 275,201,281,209,3 235,295,241,303,3 292,284,298,292,3 192,100,198,108,3 95,166,101,174,3 273,53,279,61,3 113,77,119,85,3 116,92,122,100,3 90,0,96,8,3 252,159,258,167,3 53,80,59,88,3 276,157,282,165,3 236,357,242,365,3 92,392,98,399,3'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wood', 'water', 'valley', 'peak', 'ridge']\n",
      "{0: 'wood', 1: 'water', 2: 'valley', 3: 'peak', 4: 'ridge'}\n"
     ]
    }
   ],
   "source": [
    "class_names = get_classes(classes_path)\n",
    "print(class_names)\n",
    "\n",
    "classes_dict = {}\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    classes_dict[i] = class_names[i]\n",
    "    \n",
    "print(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_path = \"../dataset/masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def create_masks(train_line):\n",
    "    line_splited = train_line.split(' ')\n",
    "    image_path, bboxes = line_splited[0], line_splited[1:]  \n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    masks = np.zeros((len(class_names), img.shape[0], img.shape[1])).astype(np.int8)\n",
    "    \n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2, class_name = list(map(int, bbox.split(',')))\n",
    "        masks[class_name][x1:x2, y1:y2] = np.array([1 for _ in range((x2 - x1) * (y2 - y1))]).reshape((x2 - x1, y2 - y1))\n",
    "\n",
    "    basename = ntpath.basename(image_path).split('.')[0] + '.npy'\n",
    "    np.save(os.path.join(masks_path, basename), masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(create_masks(train_lines[0])[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_line in train_lines:\n",
    "    create_masks(train_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for validate_line in validate_lines:\n",
    "    create_masks(validate_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_line in test_lines:\n",
    "    create_masks(test_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
