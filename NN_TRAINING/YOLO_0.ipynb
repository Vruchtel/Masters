{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Клонирование в «keras-yolo3»…\n",
      "remote: Enumerating objects: 165, done.\u001b[K\n",
      "remote: Total 165 (delta 0), reused 0 (delta 0), pack-reused 165\u001b[K\n",
      "Получение объектов: 100% (165/165), 156.01 KiB | 719.00 KiB/s, готово.\n",
      "Определение изменений: 100% (79/79), готово.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/josephofiowa/keras-yolo3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sima/SIMA/Diploma/NN_TRAINING/keras-yolo3\n"
     ]
    }
   ],
   "source": [
    "%cd keras-yolo3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_annotation.py  kmeans.py           README.roboflow.txt  yolo.py\r\n",
      "convert.py          LICENSE             train_bottleneck.py  yolov3.cfg\r\n",
      "darknet53.cfg       \u001b[0m\u001b[01;34mmodel_data\u001b[0m/         train.py             yolov3-tiny.cfg\r\n",
      "\u001b[01;34mexport\u001b[0m/             README.dataset.txt  voc_annotation.py    yolo_video.py\r\n",
      "\u001b[01;34mfont\u001b[0m/               README.md           \u001b[01;34myolo3\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sima/SIMA/Diploma/NN_TRAINING/keras-yolo3/export\n"
     ]
    }
   ],
   "source": [
    "%cd export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35m00a7a49c47d51fd16a4cbb17e2d2cf86.jpg\u001b[0m  \u001b[01;35m8233089e3c7267a3e39e6bcb0320e0d1.jpg\u001b[0m\r\n",
      "\u001b[01;35m015d0d7ff365f0b7492ff079c8c7d56c.jpg\u001b[0m  \u001b[01;35m82ac4c34d937f03cd92de0302affb393.jpg\u001b[0m\r\n",
      "\u001b[01;35m020c714dd8aee27b48e04c032cdc6c56.jpg\u001b[0m  \u001b[01;35m82e1e54400d0f2eb1ab520416dcb6e8c.jpg\u001b[0m\r\n",
      "\u001b[01;35m02741582b15e8c5871fd4f0bdd4489df.jpg\u001b[0m  \u001b[01;35m8424a55e4ad5bc1325f2c15414eb791b.jpg\u001b[0m\r\n",
      "\u001b[01;35m02bef2f0c63bd7b55246c1f29bca8350.jpg\u001b[0m  \u001b[01;35m84fc8705033f6acf0394949c550451e3.jpg\u001b[0m\r\n",
      "\u001b[01;35m0367b62e3e1075697ce387a9b668d090.jpg\u001b[0m  \u001b[01;35m851d4c592e26de69e92118db89e4aee7.jpg\u001b[0m\r\n",
      "\u001b[01;35m07d23be6925657674d77bee6b4d05ac6.jpg\u001b[0m  \u001b[01;35m855ae08bbb269e4663161fdd02584db6.jpg\u001b[0m\r\n",
      "\u001b[01;35m07d39f228cc8583410486a6cf49a0957.jpg\u001b[0m  \u001b[01;35m85badd562b70c911437b896ba28bfde7.jpg\u001b[0m\r\n",
      "\u001b[01;35m07e9133f325caf7bb29222427e0656d9.jpg\u001b[0m  \u001b[01;35m8600784f9c50989109c25cd6e5b93e0d.jpg\u001b[0m\r\n",
      "\u001b[01;35m087b4553cc7bea7162cd989e03114090.jpg\u001b[0m  \u001b[01;35m8635f1bd9f7ad5a31886b272b5bbc8b7.jpg\u001b[0m\r\n",
      "\u001b[01;35m096786c03b5a72875249701a285af99b.jpg\u001b[0m  \u001b[01;35m8853c88de4cd5dc1c83c448d25253735.jpg\u001b[0m\r\n",
      "\u001b[01;35m096ad5e720c37f05180523d6f990c176.jpg\u001b[0m  \u001b[01;35m8880b734df8ca304d1388a8e5060fa84.jpg\u001b[0m\r\n",
      "\u001b[01;35m0a1e15b9e2cd5986f0c0cbb0486c3e3a.jpg\u001b[0m  \u001b[01;35m88bbe1efba6b3589699b4263fb282450.jpg\u001b[0m\r\n",
      "\u001b[01;35m0a7275c305a9d9540dea5836003b54a6.jpg\u001b[0m  \u001b[01;35m8ba7fd5855dc20b9cf042f6b7ca75677.jpg\u001b[0m\r\n",
      "\u001b[01;35m0b4625eab10c62456930491cc3925dae.jpg\u001b[0m  \u001b[01;35m8d588ec1820669b7efe90a17a15083ce.jpg\u001b[0m\r\n",
      "\u001b[01;35m0b4a7c44d6ddb3ef61eb2b69fa24e322.jpg\u001b[0m  \u001b[01;35m8dcdbbca7eedb6006fb7450d22264c45.jpg\u001b[0m\r\n",
      "\u001b[01;35m0c60b24e695af258bdabec7d735e676a.jpg\u001b[0m  \u001b[01;35m8e30b78bf6593045ded56f3be0019b48.jpg\u001b[0m\r\n",
      "\u001b[01;35m0cfb80a069b54d5547897944f5101d42.jpg\u001b[0m  \u001b[01;35m8eb7207b7e5b9ddc4a6f626a2b3b376f.jpg\u001b[0m\r\n",
      "\u001b[01;35m0d9b19a277061df6995f60c5ad57a354.jpg\u001b[0m  \u001b[01;35m8edd0a1c70186e17cb9b10ca6349e669.jpg\u001b[0m\r\n",
      "\u001b[01;35m0e77b8e7263bb22e8ad3c67344c42ca0.jpg\u001b[0m  \u001b[01;35m8ee8c7c79e20ab65c7c61b7d2af5579d.jpg\u001b[0m\r\n",
      "\u001b[01;35m0eb05248d1504fda476fe8f503500494.jpg\u001b[0m  \u001b[01;35m902b2f5df5f3a604c1a8741ae92b9045.jpg\u001b[0m\r\n",
      "\u001b[01;35m0f987992dcc858ce8b45f18edbbd9532.jpg\u001b[0m  \u001b[01;35m90e55c97cf054208e4d41ab4bf96703a.jpg\u001b[0m\r\n",
      "\u001b[01;35m105bba5a34af61bc9562678e67cf5ba7.jpg\u001b[0m  \u001b[01;35m9218dd6767e5bf1edf8962e232c57d5b.jpg\u001b[0m\r\n",
      "\u001b[01;35m10a3683e9f96103d386e0c5909e14d1a.jpg\u001b[0m  \u001b[01;35m927e32242fd6e9566b1305d49f7ab9b5.jpg\u001b[0m\r\n",
      "\u001b[01;35m10bb2cf98d4bb6d961d028272319cc81.jpg\u001b[0m  \u001b[01;35m92db6f93840381ff43a0c819e03e0247.jpg\u001b[0m\r\n",
      "\u001b[01;35m118444cbf8df6d3e52e9ccfd414f2216.jpg\u001b[0m  \u001b[01;35m9363e589f2e2d5fa1f6d52e52790c030.jpg\u001b[0m\r\n",
      "\u001b[01;35m11bde259b1c56101baabb7feac6d7b38.jpg\u001b[0m  \u001b[01;35m93bc1d53264aaf07d5d0a1ed03810db3.jpg\u001b[0m\r\n",
      "\u001b[01;35m12e540b8fdf9de97a7e921c3342119cc.jpg\u001b[0m  \u001b[01;35m93f72fb930d1299b054e54e7aa770fe7.jpg\u001b[0m\r\n",
      "\u001b[01;35m165f6e3b72cdc27b1d4b4dd8a519e187.jpg\u001b[0m  \u001b[01;35m94b350a4c642c663a21bbd27cdd3a80b.jpg\u001b[0m\r\n",
      "\u001b[01;35m16824455a0af6cace6fc5c4cb9fc2ebd.jpg\u001b[0m  \u001b[01;35m969f39653bbccb8c83c30fff3090b87e.jpg\u001b[0m\r\n",
      "\u001b[01;35m16e1abb1e2a73809ed65da01ae26dbc0.jpg\u001b[0m  \u001b[01;35m986c76b6068425fa83ac7e6579a6a338.jpg\u001b[0m\r\n",
      "\u001b[01;35m172d3c53e283e45d9435803b04ca608d.jpg\u001b[0m  \u001b[01;35m992366797edcde33bb48296bc6200e91.jpg\u001b[0m\r\n",
      "\u001b[01;35m176b28b5c417f39a9e5d37545fca5b4c.jpg\u001b[0m  \u001b[01;35m99eee4390bb66bc3d180c55520cbbaca.jpg\u001b[0m\r\n",
      "\u001b[01;35m177bd0cc1371a81564c54de66dedc20e.jpg\u001b[0m  \u001b[01;35m9a57a48d7397becaa5390e3c4a6bdb30.jpg\u001b[0m\r\n",
      "\u001b[01;35m1886b97f719ac1022fabd0a3bf5c563a.jpg\u001b[0m  \u001b[01;35m9a810759181ca99becda485be80f6ff3.jpg\u001b[0m\r\n",
      "\u001b[01;35m18d36dd4777f7b1ba412aba67de41864.jpg\u001b[0m  \u001b[01;35m9adc916372026610d8a4c0235b311ea6.jpg\u001b[0m\r\n",
      "\u001b[01;35m19d20716426f924d1eccc3967bd9877f.jpg\u001b[0m  \u001b[01;35m9b56c34516394c520c9d2923615ecfb5.jpg\u001b[0m\r\n",
      "\u001b[01;35m1aef9e7e3d6e134349ff13f0c067c913.jpg\u001b[0m  \u001b[01;35m9c479a75d22b7a99d08a52f331c4f9da.jpg\u001b[0m\r\n",
      "\u001b[01;35m1b6230ce157f6d1d9bb5e9a86200eaeb.jpg\u001b[0m  \u001b[01;35m9e1d53b9ffde4138aba13db611c57e79.jpg\u001b[0m\r\n",
      "\u001b[01;35m1f27b8bfdd2a026e86f3bd52fc74713d.jpg\u001b[0m  \u001b[01;35m9eae6b69ac82e2a83f229f1bdf550ed5.jpg\u001b[0m\r\n",
      "\u001b[01;35m2381a64086777c4fffdf2d48e96e9db1.jpg\u001b[0m  \u001b[01;35m9f28b8ab88bebab972d29fdcfb65d023.jpg\u001b[0m\r\n",
      "\u001b[01;35m23fb1182e24571726aa14f0b6a2dd3b5.jpg\u001b[0m  \u001b[01;35m9f61f243bb3e500c4f79b5eb74855271.jpg\u001b[0m\r\n",
      "\u001b[01;35m24fd4e9c6957c1b357608dea2e38f74a.jpg\u001b[0m  \u001b[01;35ma0d0fc97dd4b571537d1869ad70257ad.jpg\u001b[0m\r\n",
      "\u001b[01;35m251c01831213c18daea2b2be53685089.jpg\u001b[0m  \u001b[01;35ma3ab0c50999443cd38e73ce8b94d430b.jpg\u001b[0m\r\n",
      "\u001b[01;35m252ae1f9e38a363b275ed831dc490c20.jpg\u001b[0m  \u001b[01;35ma669f1cd807ae04202b1f7db3d531e56.jpg\u001b[0m\r\n",
      "\u001b[01;35m2798cc09b32df55229cfec15c88365f6.jpg\u001b[0m  \u001b[01;35ma6bde186018cb39641cd2a0968a977f0.jpg\u001b[0m\r\n",
      "\u001b[01;35m27a9253a655ee2bb518328b119d72efe.jpg\u001b[0m  \u001b[01;35ma74a6f4768a06e79668f59bda300d4ef.jpg\u001b[0m\r\n",
      "\u001b[01;35m28a529d6561a85458a45f07180c713c3.jpg\u001b[0m  \u001b[01;35ma74d4afdd667246ae12d84e5dff09f29.jpg\u001b[0m\r\n",
      "\u001b[01;35m28aac29a2d0b7aace86802dc3aa800cc.jpg\u001b[0m  \u001b[01;35ma947725297926631323aeba9fb4131bb.jpg\u001b[0m\r\n",
      "\u001b[01;35m29177db0e9271acf94dcd6e33c688188.jpg\u001b[0m  \u001b[01;35maa650a313329f53bf5b2e51f6235768d.jpg\u001b[0m\r\n",
      "\u001b[01;35m2b1fe60f68b0e32d10af65687e4885c6.jpg\u001b[0m  \u001b[01;35mac5b65caa16f9acf0ecdb3799921f824.jpg\u001b[0m\r\n",
      "\u001b[01;35m2db93dd3e276a1f2c14a7e26821975e8.jpg\u001b[0m  \u001b[01;35maca2a22b2a4c614a9ee7d034af7fb76d.jpg\u001b[0m\r\n",
      "\u001b[01;35m2e749a0118f16e466d297616bd0d06d7.jpg\u001b[0m  \u001b[01;35mad2fa40c2465a551cb406470e9254aed.jpg\u001b[0m\r\n",
      "\u001b[01;35m2eb1b773702b6096dfd836b8add1e74a.jpg\u001b[0m  \u001b[01;35mad9f2fe474835af2f368732cb1927a8b.jpg\u001b[0m\r\n",
      "\u001b[01;35m2f4a35adc451337a30d055dd1aafe189.jpg\u001b[0m  \u001b[01;35mafc1ce7b09cbc468cf945a0319f1c073.jpg\u001b[0m\r\n",
      "\u001b[01;35m32807b3a46353a482193905c528837da.jpg\u001b[0m  _annotations.txt\r\n",
      "\u001b[01;35m329190f7a4175a9f6d44151b19694b27.jpg\u001b[0m  \u001b[01;35mb1f23cc43f9309a5a6946d7bd9a74909.jpg\u001b[0m\r\n",
      "\u001b[01;35m34873f2057a6297623315ec3947181d7.jpg\u001b[0m  \u001b[01;35mb36eab7c22a7a59c94f6c52b370afc14.jpg\u001b[0m\r\n",
      "\u001b[01;35m3639fd697d9d61c2f430abe2b778e5e6.jpg\u001b[0m  \u001b[01;35mb56c485cf9f485d3f426256cbc6f6518.jpg\u001b[0m\r\n",
      "\u001b[01;35m37a688698a6d6a34c1753b55ac876705.jpg\u001b[0m  \u001b[01;35mb66c5699545360add255a84e972aacdf.jpg\u001b[0m\r\n",
      "\u001b[01;35m39b72b5383752892d260f4c9edf0a284.jpg\u001b[0m  \u001b[01;35mb6c077013b3ba8e3b05135c52fd61b4e.jpg\u001b[0m\r\n",
      "\u001b[01;35m3a6618d8ee1c8a0c207e46950e53e3fc.jpg\u001b[0m  \u001b[01;35mb7e80d096ca37b0855ce624ad4ef4183.jpg\u001b[0m\r\n",
      "\u001b[01;35m3cf73d42c1afae0c5a8615616140d9da.jpg\u001b[0m  \u001b[01;35mb8a45c62c84a1eab84150e11a96cbda8.jpg\u001b[0m\r\n",
      "\u001b[01;35m3d0ac7238cb05f41935dff4a18435015.jpg\u001b[0m  \u001b[01;35mba0f307595f40126016214fd02a7544e.jpg\u001b[0m\r\n",
      "\u001b[01;35m3d535fc202523f86d91dc5b42660ef84.jpg\u001b[0m  \u001b[01;35mbbadb16396763be9fb23a354c44539a4.jpg\u001b[0m\r\n",
      "\u001b[01;35m3e00d4cc024a68dd17a7cf3dc1deea5e.jpg\u001b[0m  \u001b[01;35mbcc98500206542d85176a023a9c62bab.jpg\u001b[0m\r\n",
      "\u001b[01;35m3e68e58af4b396f7d6f666a347377916.jpg\u001b[0m  \u001b[01;35mbf0667226a5f69aa0c19872567751a99.jpg\u001b[0m\r\n",
      "\u001b[01;35m3e6d6dae7ee52c1595f3abd91feeacad.jpg\u001b[0m  \u001b[01;35mbf6c6d6d4468bf4e7526be85733decdf.jpg\u001b[0m\r\n",
      "\u001b[01;35m3ea7da5aee9a362c1c65c07dc6257c88.jpg\u001b[0m  \u001b[01;35mbf832f37e4a4fe656aedc466fb456323.jpg\u001b[0m\r\n",
      "\u001b[01;35m3ee8e15976bbb4c279d81d46d87b85e7.jpg\u001b[0m  \u001b[01;35mc10d57818ce6bcd08a648cf69e7914f2.jpg\u001b[0m\r\n",
      "\u001b[01;35m3f3699151e86cb4e31f3d461cdf7c06b.jpg\u001b[0m  \u001b[01;35mc1f4910f015c809e6527ebab81f17acf.jpg\u001b[0m\r\n",
      "\u001b[01;35m3fcd831b3c679e7ab6f6f418e40f0b7b.jpg\u001b[0m  \u001b[01;35mc29a24a3d468b854e9b593bc4a6ce173.jpg\u001b[0m\r\n",
      "\u001b[01;35m4122d92c06fef242b531d4a8e7571631.jpg\u001b[0m  \u001b[01;35mc2ea38afc21f50539154964fe393acbb.jpg\u001b[0m\r\n",
      "\u001b[01;35m4190dbe00a9dcfbd27208f9b1c956e33.jpg\u001b[0m  \u001b[01;35mc6078c7dd44948b063d0dddb7968520d.jpg\u001b[0m\r\n",
      "\u001b[01;35m41e8a04c57a9f20ff6d6f954eb736a97.jpg\u001b[0m  \u001b[01;35mc6ca3942861280a09bd1dfc506618b64.jpg\u001b[0m\r\n",
      "\u001b[01;35m438a99bf2163df745c9303c7650beea7.jpg\u001b[0m  \u001b[01;35mc77ee8707cd44869b3689182d9664b91.jpg\u001b[0m\r\n",
      "\u001b[01;35m441a567578734de915735b69ac018342.jpg\u001b[0m  \u001b[01;35mcab31a0ee5e50f0999370ec0c1be00d0.jpg\u001b[0m\r\n",
      "\u001b[01;35m44a689c225b3cef9ce68c669e37c7478.jpg\u001b[0m  \u001b[01;35mcad3ea6316048ecc5873061e703116b2.jpg\u001b[0m\r\n",
      "\u001b[01;35m4647d7da27a40e760e4f21ef6d5a219f.jpg\u001b[0m  \u001b[01;35mcc133d49c27d6b1e979d4b797b43e676.jpg\u001b[0m\r\n",
      "\u001b[01;35m4673f994f60a2ea7afdddc1b752947c0.jpg\u001b[0m  \u001b[01;35mcceee8ec03d0ec8cc1cf8c5338a5496d.jpg\u001b[0m\r\n",
      "\u001b[01;35m46d2ecc7004c3de4ab1180ed4d8772f8.jpg\u001b[0m  \u001b[01;35mce044ed34208e35a977a36cd8cf6136a.jpg\u001b[0m\r\n",
      "\u001b[01;35m471bd4e081267ec5a1f7f96e914a08e0.jpg\u001b[0m  \u001b[01;35mce19e7a8e500cadd70a523ac2c7f508e.jpg\u001b[0m\r\n",
      "\u001b[01;35m4751b958e98a485f42b5bb91fadf5ef6.jpg\u001b[0m  \u001b[01;35mce54723d69985c8c9e909f55ff59240b.jpg\u001b[0m\r\n",
      "\u001b[01;35m47671c8812a971f5197441084ced4912.jpg\u001b[0m  \u001b[01;35mcf9d4c377c2482ea2857a0f9dd207993.jpg\u001b[0m\r\n",
      "\u001b[01;35m4903df89ce9d5d1c4141ac4cfe4af12d.jpg\u001b[0m  _classes.txt\r\n",
      "\u001b[01;35m49611b054e12fe1964af42a2a5f1293f.jpg\u001b[0m  \u001b[01;35md0e26d9856c5330993fd0ac06fbb348a.jpg\u001b[0m\r\n",
      "\u001b[01;35m49d31dc46d8f446df3bf6c72b79d4a73.jpg\u001b[0m  \u001b[01;35md1db98c2769632aa5c3b590f8dd25a01.jpg\u001b[0m\r\n",
      "\u001b[01;35m4a0ec96e59a6ecc577f9194ddb3d860d.jpg\u001b[0m  \u001b[01;35md215dd551052cb175c7433a759ce04b4.jpg\u001b[0m\r\n",
      "\u001b[01;35m4a615740264dd7042b5b95843ddbc88b.jpg\u001b[0m  \u001b[01;35md31891ed8c146345589264967eeb63ce.jpg\u001b[0m\r\n",
      "\u001b[01;35m4b31840d2cc06fb1b309a76c0a12ff81.jpg\u001b[0m  \u001b[01;35md4371793c4a59267c64fdce04338b549.jpg\u001b[0m\r\n",
      "\u001b[01;35m4bb19fb85ec43cb59128c4876b769b6a.jpg\u001b[0m  \u001b[01;35md46bd0f705188dd46e38d84b1c79a23b.jpg\u001b[0m\r\n",
      "\u001b[01;35m4c5b94551e57ab04354d77c8b71ce7be.jpg\u001b[0m  \u001b[01;35md50a1cfaf3ff21502f27b93014f3e9c0.jpg\u001b[0m\r\n",
      "\u001b[01;35m4c6101c3f30d730a4a0ac27d45401950.jpg\u001b[0m  \u001b[01;35md528791406f2caf1552084e2a2fde900.jpg\u001b[0m\r\n",
      "\u001b[01;35m4c61293a1cf38b1d057ce892a5fd47c9.jpg\u001b[0m  \u001b[01;35md58efc544cf00101e0f99d0256c45234.jpg\u001b[0m\r\n",
      "\u001b[01;35m4cf686cb8e2cdb9178c01f040fc1b86c.jpg\u001b[0m  \u001b[01;35md75c53a2a4d0b9232153b52c0d0d7ede.jpg\u001b[0m\r\n",
      "\u001b[01;35m4d711d905ba244ac7d1d5cf6f47ab5d4.jpg\u001b[0m  \u001b[01;35md7674c0e7890c303967c8cccc6204375.jpg\u001b[0m\r\n",
      "\u001b[01;35m4e1f70a737a49533a64d5b9a750591df.jpg\u001b[0m  \u001b[01;35md8f4662421281456582717ea45e0669f.jpg\u001b[0m\r\n",
      "\u001b[01;35m4fa05947777eb333fdf7fef7f6a39aa3.jpg\u001b[0m  \u001b[01;35md93a5e6c76001207bf1ef82e4064e6d0.jpg\u001b[0m\r\n",
      "\u001b[01;35m52195ec09cfde7738f514483ab0faab5.jpg\u001b[0m  \u001b[01;35mda8b427e50257c69982cddfa5431e0ba.jpg\u001b[0m\r\n",
      "\u001b[01;35m5251a9548976dcd9e9cf377f968d5110.jpg\u001b[0m  \u001b[01;35mdc0ce38e8224d4961e9be7bdeecd7a80.jpg\u001b[0m\r\n",
      "\u001b[01;35m53ad46f0d8fc0af89de3f0a4b7373daf.jpg\u001b[0m  \u001b[01;35mdc4fea6db87e6b97b6060c788fcb38ed.jpg\u001b[0m\r\n",
      "\u001b[01;35m5537e84bf703323dea17e99fc1e46fbe.jpg\u001b[0m  \u001b[01;35mdd07c7329f95af9afd13c62523d95ce8.jpg\u001b[0m\r\n",
      "\u001b[01;35m5b26b81380ab1bec7867d3d102d83f74.jpg\u001b[0m  \u001b[01;35mdeb2a655d915e2aa5bb8652977b460c3.jpg\u001b[0m\r\n",
      "\u001b[01;35m5ca7f0cb1c500554e65ad031190f8e9f.jpg\u001b[0m  \u001b[01;35mdedb7c63796710f0a598e3b7baeed76a.jpg\u001b[0m\r\n",
      "\u001b[01;35m5e3fb661f1ac554dff004359df72387e.jpg\u001b[0m  \u001b[01;35mdf7bf23db19e607646a6c424a8d39067.jpg\u001b[0m\r\n",
      "\u001b[01;35m5f716918bfde18a52c093707c4921789.jpg\u001b[0m  \u001b[01;35mdfb3847dad2a3a269cad51f6e99b23fd.jpg\u001b[0m\r\n",
      "\u001b[01;35m60aeeff2a621a8ec9cb371cd00317c2b.jpg\u001b[0m  \u001b[01;35me2ead6cef23be53d6d1e5ecd22ba90cf.jpg\u001b[0m\r\n",
      "\u001b[01;35m61320a49499bda6bb7f321c35bb53d9d.jpg\u001b[0m  \u001b[01;35me326857ff4207758d9dba05d756c6cf6.jpg\u001b[0m\r\n",
      "\u001b[01;35m615cc6dc2a47c67afb931d9a51824037.jpg\u001b[0m  \u001b[01;35me3c49ae97c37ec7b2a05b18600efac5d.jpg\u001b[0m\r\n",
      "\u001b[01;35m62c6410f0717a807c41d40cf6b4964e1.jpg\u001b[0m  \u001b[01;35me43db05532253f717b6045a0fd6215b0.jpg\u001b[0m\r\n",
      "\u001b[01;35m65c0d23bbc6c2d77c4a0488db9abac77.jpg\u001b[0m  \u001b[01;35me562ee6ea0737d165b1da67624dd8987.jpg\u001b[0m\r\n",
      "\u001b[01;35m663e7be934f3039cdd089fb286908ecf.jpg\u001b[0m  \u001b[01;35me7c744c80cf1cfbb05487523bd31865d.jpg\u001b[0m\r\n",
      "\u001b[01;35m6685801852e1619c3db6c5b1a89f804f.jpg\u001b[0m  \u001b[01;35me7c89abb4eb1fc215565e3a6ba315586.jpg\u001b[0m\r\n",
      "\u001b[01;35m679cdadab56df2b7a2219c2dc991405a.jpg\u001b[0m  \u001b[01;35me84751775955296abea5c02e9f7f76cf.jpg\u001b[0m\r\n",
      "\u001b[01;35m6b2a7d11616d09ca272839f2c9e78c8d.jpg\u001b[0m  \u001b[01;35me8f60c0e9e679a823c65ca13ac5fa77a.jpg\u001b[0m\r\n",
      "\u001b[01;35m6bc9b8a32fd443dc481e721dfae8bd6a.jpg\u001b[0m  \u001b[01;35me928eeb105e859d381384d51dfba74f0.jpg\u001b[0m\r\n",
      "\u001b[01;35m6c3bcb67b1481fb40443deb8d694955e.jpg\u001b[0m  \u001b[01;35mec021e67720e0ac5cc75bbcf26f03945.jpg\u001b[0m\r\n",
      "\u001b[01;35m6d7ed947bf52caa7113b4d012a1d7d75.jpg\u001b[0m  \u001b[01;35mec48ef12e5c2da9192d917dd4d5c38ad.jpg\u001b[0m\r\n",
      "\u001b[01;35m6da0ea5f251340c9505b914a7ea78082.jpg\u001b[0m  \u001b[01;35mec610cade260cff00e4d5733c679c3de.jpg\u001b[0m\r\n",
      "\u001b[01;35m6e021f7b2c75e65b134f1dfb4465f5df.jpg\u001b[0m  \u001b[01;35mece61f608b3818a78335fbb492c835b7.jpg\u001b[0m\r\n",
      "\u001b[01;35m6e25b8e19ae48f3872bd5eab3d578e09.jpg\u001b[0m  \u001b[01;35meedf2b3d9c39bba074a186368853b39f.jpg\u001b[0m\r\n",
      "\u001b[01;35m6e331e23c51d04f0eceea1f9023f3ee9.jpg\u001b[0m  \u001b[01;35mef2520d3f775b4a6b7f756ceeafa1d5e.jpg\u001b[0m\r\n",
      "\u001b[01;35m7010666befa8b4202ae1f319c259fd8e.jpg\u001b[0m  \u001b[01;35mef30e6c0211bb751e9df4ab3a14d894c.jpg\u001b[0m\r\n",
      "\u001b[01;35m708034816396f76630b4b1813192e302.jpg\u001b[0m  \u001b[01;35mef4ed5721285d6a77aee0c9e30e8df02.jpg\u001b[0m\r\n",
      "\u001b[01;35m717051c1cb096a53794b246d4cf038a6.jpg\u001b[0m  \u001b[01;35mefbf0cfc24d8a91265deaa45d05af584.jpg\u001b[0m\r\n",
      "\u001b[01;35m71ad7edd0118ef2b86663002a70d585f.jpg\u001b[0m  \u001b[01;35mf01aaf35d0d831ef8fa0777719784c19.jpg\u001b[0m\r\n",
      "\u001b[01;35m73555f112907e86bfafed44f71a148ef.jpg\u001b[0m  \u001b[01;35mf05a78bda48dce1977b0c908d0b7a69a.jpg\u001b[0m\r\n",
      "\u001b[01;35m73fdd346c54e5d29fa548a7e7dbff175.jpg\u001b[0m  \u001b[01;35mf0caf176dc8ec78aa856f2b0f46bd54e.jpg\u001b[0m\r\n",
      "\u001b[01;35m75e29c304561ffc13a23c8f7f70a7c36.jpg\u001b[0m  \u001b[01;35mf2b132da5554bb6206f3ac543dc24614.jpg\u001b[0m\r\n",
      "\u001b[01;35m76437ea0f0e279a6a41f194c2c2b1aa9.jpg\u001b[0m  \u001b[01;35mf31caa81af9764a371336852e1f5b311.jpg\u001b[0m\r\n",
      "\u001b[01;35m78fbe3bd1099d0a705be5b548b1cc4c8.jpg\u001b[0m  \u001b[01;35mf3cd7d7511cd74144f9a36f454a41938.jpg\u001b[0m\r\n",
      "\u001b[01;35m796613514b414f81a14b3ac2f0ae4107.jpg\u001b[0m  \u001b[01;35mf44f94809fd9d56b6d61de01e39f6564.jpg\u001b[0m\r\n",
      "\u001b[01;35m798aa55f3762983463971aec7c614d79.jpg\u001b[0m  \u001b[01;35mf4ad57f26fb743a960adf55a3d529e8f.jpg\u001b[0m\r\n",
      "\u001b[01;35m7995269764aa1bc8a0ae361a75ab7940.jpg\u001b[0m  \u001b[01;35mf6ef8c1299edc5a8e917b888992bda52.jpg\u001b[0m\r\n",
      "\u001b[01;35m79bb62bc2c7e539d45b85d4b4924832f.jpg\u001b[0m  \u001b[01;35mf7a4a57cdbca6047cdaa0276a480f37d.jpg\u001b[0m\r\n",
      "\u001b[01;35m7b37d7ccc4b31387a48cc9715739e0e3.jpg\u001b[0m  \u001b[01;35mf8630684319e46b68de7ce8d2304a302.jpg\u001b[0m\r\n",
      "\u001b[01;35m7c62d25fd0c77f8c32bc6b781c055df3.jpg\u001b[0m  \u001b[01;35mf8ecce66d12f2fa1ce56da09f655c701.jpg\u001b[0m\r\n",
      "\u001b[01;35m7c87d6838d146122ef94f2f78494adb2.jpg\u001b[0m  \u001b[01;35mf91c54cdd724a292b6b3d4316ea0a7b6.jpg\u001b[0m\r\n",
      "\u001b[01;35m7cb1383efcf128f06b9cef3ba1ed5f7a.jpg\u001b[0m  \u001b[01;35mf9215ce495aad438e56ad01220045662.jpg\u001b[0m\r\n",
      "\u001b[01;35m7ccd5103b5b381680536745ce01a875a.jpg\u001b[0m  \u001b[01;35mfa95f13af4a64802510d44ad67aa705c.jpg\u001b[0m\r\n",
      "\u001b[01;35m7d379742516b2c1a3f1e19fbe4bce095.jpg\u001b[0m  \u001b[01;35mfab98107e404bec110fbec7aa04bf6a6.jpg\u001b[0m\r\n",
      "\u001b[01;35m7ef06bd5a52cd8ca24c505b6b05703de.jpg\u001b[0m  \u001b[01;35mfbe3f6991b987b1ae5be069bc5e100ed.jpg\u001b[0m\r\n",
      "\u001b[01;35m7fa17062f732a1d58470ab4adbc1f245.jpg\u001b[0m  \u001b[01;35mfbf15139f38a46e02b5f4061c0c9b08f.jpg\u001b[0m\r\n",
      "\u001b[01;35m804339c5f8807fe987d059bf7bc4e516.jpg\u001b[0m  \u001b[01;35mfd116ea829fb9c6c6604c3a7baa70357.jpg\u001b[0m\r\n",
      "\u001b[01;35m8124fe4c673844b230c5e5c95e8f8817.jpg\u001b[0m  \u001b[01;35mfd13f39384b64a1447956b8f48271eb5.jpg\u001b[0m\r\n",
      "\u001b[01;35m818ba349eb81aafbfbb7577d2c2dd3b5.jpg\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv * ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sima/SIMA/Diploma/NN_TRAINING/keras-yolo3\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35m00a7a49c47d51fd16a4cbb17e2d2cf86.jpg\u001b[0m  \u001b[01;35m8635f1bd9f7ad5a31886b272b5bbc8b7.jpg\u001b[0m\r\n",
      "\u001b[01;35m015d0d7ff365f0b7492ff079c8c7d56c.jpg\u001b[0m  \u001b[01;35m8853c88de4cd5dc1c83c448d25253735.jpg\u001b[0m\r\n",
      "\u001b[01;35m020c714dd8aee27b48e04c032cdc6c56.jpg\u001b[0m  \u001b[01;35m8880b734df8ca304d1388a8e5060fa84.jpg\u001b[0m\r\n",
      "\u001b[01;35m02741582b15e8c5871fd4f0bdd4489df.jpg\u001b[0m  \u001b[01;35m88bbe1efba6b3589699b4263fb282450.jpg\u001b[0m\r\n",
      "\u001b[01;35m02bef2f0c63bd7b55246c1f29bca8350.jpg\u001b[0m  \u001b[01;35m8ba7fd5855dc20b9cf042f6b7ca75677.jpg\u001b[0m\r\n",
      "\u001b[01;35m0367b62e3e1075697ce387a9b668d090.jpg\u001b[0m  \u001b[01;35m8d588ec1820669b7efe90a17a15083ce.jpg\u001b[0m\r\n",
      "\u001b[01;35m07d23be6925657674d77bee6b4d05ac6.jpg\u001b[0m  \u001b[01;35m8dcdbbca7eedb6006fb7450d22264c45.jpg\u001b[0m\r\n",
      "\u001b[01;35m07d39f228cc8583410486a6cf49a0957.jpg\u001b[0m  \u001b[01;35m8e30b78bf6593045ded56f3be0019b48.jpg\u001b[0m\r\n",
      "\u001b[01;35m07e9133f325caf7bb29222427e0656d9.jpg\u001b[0m  \u001b[01;35m8eb7207b7e5b9ddc4a6f626a2b3b376f.jpg\u001b[0m\r\n",
      "\u001b[01;35m087b4553cc7bea7162cd989e03114090.jpg\u001b[0m  \u001b[01;35m8edd0a1c70186e17cb9b10ca6349e669.jpg\u001b[0m\r\n",
      "\u001b[01;35m096786c03b5a72875249701a285af99b.jpg\u001b[0m  \u001b[01;35m8ee8c7c79e20ab65c7c61b7d2af5579d.jpg\u001b[0m\r\n",
      "\u001b[01;35m096ad5e720c37f05180523d6f990c176.jpg\u001b[0m  \u001b[01;35m902b2f5df5f3a604c1a8741ae92b9045.jpg\u001b[0m\r\n",
      "\u001b[01;35m0a1e15b9e2cd5986f0c0cbb0486c3e3a.jpg\u001b[0m  \u001b[01;35m90e55c97cf054208e4d41ab4bf96703a.jpg\u001b[0m\r\n",
      "\u001b[01;35m0a7275c305a9d9540dea5836003b54a6.jpg\u001b[0m  \u001b[01;35m9218dd6767e5bf1edf8962e232c57d5b.jpg\u001b[0m\r\n",
      "\u001b[01;35m0b4625eab10c62456930491cc3925dae.jpg\u001b[0m  \u001b[01;35m927e32242fd6e9566b1305d49f7ab9b5.jpg\u001b[0m\r\n",
      "\u001b[01;35m0b4a7c44d6ddb3ef61eb2b69fa24e322.jpg\u001b[0m  \u001b[01;35m92db6f93840381ff43a0c819e03e0247.jpg\u001b[0m\r\n",
      "\u001b[01;35m0c60b24e695af258bdabec7d735e676a.jpg\u001b[0m  \u001b[01;35m9363e589f2e2d5fa1f6d52e52790c030.jpg\u001b[0m\r\n",
      "\u001b[01;35m0cfb80a069b54d5547897944f5101d42.jpg\u001b[0m  \u001b[01;35m93bc1d53264aaf07d5d0a1ed03810db3.jpg\u001b[0m\r\n",
      "\u001b[01;35m0d9b19a277061df6995f60c5ad57a354.jpg\u001b[0m  \u001b[01;35m93f72fb930d1299b054e54e7aa770fe7.jpg\u001b[0m\r\n",
      "\u001b[01;35m0e77b8e7263bb22e8ad3c67344c42ca0.jpg\u001b[0m  \u001b[01;35m94b350a4c642c663a21bbd27cdd3a80b.jpg\u001b[0m\r\n",
      "\u001b[01;35m0eb05248d1504fda476fe8f503500494.jpg\u001b[0m  \u001b[01;35m969f39653bbccb8c83c30fff3090b87e.jpg\u001b[0m\r\n",
      "\u001b[01;35m0f987992dcc858ce8b45f18edbbd9532.jpg\u001b[0m  \u001b[01;35m986c76b6068425fa83ac7e6579a6a338.jpg\u001b[0m\r\n",
      "\u001b[01;35m105bba5a34af61bc9562678e67cf5ba7.jpg\u001b[0m  \u001b[01;35m992366797edcde33bb48296bc6200e91.jpg\u001b[0m\r\n",
      "\u001b[01;35m10a3683e9f96103d386e0c5909e14d1a.jpg\u001b[0m  \u001b[01;35m99eee4390bb66bc3d180c55520cbbaca.jpg\u001b[0m\r\n",
      "\u001b[01;35m10bb2cf98d4bb6d961d028272319cc81.jpg\u001b[0m  \u001b[01;35m9a57a48d7397becaa5390e3c4a6bdb30.jpg\u001b[0m\r\n",
      "\u001b[01;35m118444cbf8df6d3e52e9ccfd414f2216.jpg\u001b[0m  \u001b[01;35m9a810759181ca99becda485be80f6ff3.jpg\u001b[0m\r\n",
      "\u001b[01;35m11bde259b1c56101baabb7feac6d7b38.jpg\u001b[0m  \u001b[01;35m9adc916372026610d8a4c0235b311ea6.jpg\u001b[0m\r\n",
      "\u001b[01;35m12e540b8fdf9de97a7e921c3342119cc.jpg\u001b[0m  \u001b[01;35m9b56c34516394c520c9d2923615ecfb5.jpg\u001b[0m\r\n",
      "\u001b[01;35m165f6e3b72cdc27b1d4b4dd8a519e187.jpg\u001b[0m  \u001b[01;35m9c479a75d22b7a99d08a52f331c4f9da.jpg\u001b[0m\r\n",
      "\u001b[01;35m16824455a0af6cace6fc5c4cb9fc2ebd.jpg\u001b[0m  \u001b[01;35m9e1d53b9ffde4138aba13db611c57e79.jpg\u001b[0m\r\n",
      "\u001b[01;35m16e1abb1e2a73809ed65da01ae26dbc0.jpg\u001b[0m  \u001b[01;35m9eae6b69ac82e2a83f229f1bdf550ed5.jpg\u001b[0m\r\n",
      "\u001b[01;35m172d3c53e283e45d9435803b04ca608d.jpg\u001b[0m  \u001b[01;35m9f28b8ab88bebab972d29fdcfb65d023.jpg\u001b[0m\r\n",
      "\u001b[01;35m176b28b5c417f39a9e5d37545fca5b4c.jpg\u001b[0m  \u001b[01;35m9f61f243bb3e500c4f79b5eb74855271.jpg\u001b[0m\r\n",
      "\u001b[01;35m177bd0cc1371a81564c54de66dedc20e.jpg\u001b[0m  \u001b[01;35ma0d0fc97dd4b571537d1869ad70257ad.jpg\u001b[0m\r\n",
      "\u001b[01;35m1886b97f719ac1022fabd0a3bf5c563a.jpg\u001b[0m  \u001b[01;35ma3ab0c50999443cd38e73ce8b94d430b.jpg\u001b[0m\r\n",
      "\u001b[01;35m18d36dd4777f7b1ba412aba67de41864.jpg\u001b[0m  \u001b[01;35ma669f1cd807ae04202b1f7db3d531e56.jpg\u001b[0m\r\n",
      "\u001b[01;35m19d20716426f924d1eccc3967bd9877f.jpg\u001b[0m  \u001b[01;35ma6bde186018cb39641cd2a0968a977f0.jpg\u001b[0m\r\n",
      "\u001b[01;35m1aef9e7e3d6e134349ff13f0c067c913.jpg\u001b[0m  \u001b[01;35ma74a6f4768a06e79668f59bda300d4ef.jpg\u001b[0m\r\n",
      "\u001b[01;35m1b6230ce157f6d1d9bb5e9a86200eaeb.jpg\u001b[0m  \u001b[01;35ma74d4afdd667246ae12d84e5dff09f29.jpg\u001b[0m\r\n",
      "\u001b[01;35m1f27b8bfdd2a026e86f3bd52fc74713d.jpg\u001b[0m  \u001b[01;35ma947725297926631323aeba9fb4131bb.jpg\u001b[0m\r\n",
      "\u001b[01;35m2381a64086777c4fffdf2d48e96e9db1.jpg\u001b[0m  \u001b[01;35maa650a313329f53bf5b2e51f6235768d.jpg\u001b[0m\r\n",
      "\u001b[01;35m23fb1182e24571726aa14f0b6a2dd3b5.jpg\u001b[0m  \u001b[01;35mac5b65caa16f9acf0ecdb3799921f824.jpg\u001b[0m\r\n",
      "\u001b[01;35m24fd4e9c6957c1b357608dea2e38f74a.jpg\u001b[0m  \u001b[01;35maca2a22b2a4c614a9ee7d034af7fb76d.jpg\u001b[0m\r\n",
      "\u001b[01;35m251c01831213c18daea2b2be53685089.jpg\u001b[0m  \u001b[01;35mad2fa40c2465a551cb406470e9254aed.jpg\u001b[0m\r\n",
      "\u001b[01;35m252ae1f9e38a363b275ed831dc490c20.jpg\u001b[0m  \u001b[01;35mad9f2fe474835af2f368732cb1927a8b.jpg\u001b[0m\r\n",
      "\u001b[01;35m2798cc09b32df55229cfec15c88365f6.jpg\u001b[0m  \u001b[01;35mafc1ce7b09cbc468cf945a0319f1c073.jpg\u001b[0m\r\n",
      "\u001b[01;35m27a9253a655ee2bb518328b119d72efe.jpg\u001b[0m  _annotations.txt\r\n",
      "\u001b[01;35m28a529d6561a85458a45f07180c713c3.jpg\u001b[0m  \u001b[01;35mb1f23cc43f9309a5a6946d7bd9a74909.jpg\u001b[0m\r\n",
      "\u001b[01;35m28aac29a2d0b7aace86802dc3aa800cc.jpg\u001b[0m  \u001b[01;35mb36eab7c22a7a59c94f6c52b370afc14.jpg\u001b[0m\r\n",
      "\u001b[01;35m29177db0e9271acf94dcd6e33c688188.jpg\u001b[0m  \u001b[01;35mb56c485cf9f485d3f426256cbc6f6518.jpg\u001b[0m\r\n",
      "\u001b[01;35m2b1fe60f68b0e32d10af65687e4885c6.jpg\u001b[0m  \u001b[01;35mb66c5699545360add255a84e972aacdf.jpg\u001b[0m\r\n",
      "\u001b[01;35m2db93dd3e276a1f2c14a7e26821975e8.jpg\u001b[0m  \u001b[01;35mb6c077013b3ba8e3b05135c52fd61b4e.jpg\u001b[0m\r\n",
      "\u001b[01;35m2e749a0118f16e466d297616bd0d06d7.jpg\u001b[0m  \u001b[01;35mb7e80d096ca37b0855ce624ad4ef4183.jpg\u001b[0m\r\n",
      "\u001b[01;35m2eb1b773702b6096dfd836b8add1e74a.jpg\u001b[0m  \u001b[01;35mb8a45c62c84a1eab84150e11a96cbda8.jpg\u001b[0m\r\n",
      "\u001b[01;35m2f4a35adc451337a30d055dd1aafe189.jpg\u001b[0m  \u001b[01;35mba0f307595f40126016214fd02a7544e.jpg\u001b[0m\r\n",
      "\u001b[01;35m32807b3a46353a482193905c528837da.jpg\u001b[0m  \u001b[01;35mbbadb16396763be9fb23a354c44539a4.jpg\u001b[0m\r\n",
      "\u001b[01;35m329190f7a4175a9f6d44151b19694b27.jpg\u001b[0m  \u001b[01;35mbcc98500206542d85176a023a9c62bab.jpg\u001b[0m\r\n",
      "\u001b[01;35m34873f2057a6297623315ec3947181d7.jpg\u001b[0m  \u001b[01;35mbf0667226a5f69aa0c19872567751a99.jpg\u001b[0m\r\n",
      "\u001b[01;35m3639fd697d9d61c2f430abe2b778e5e6.jpg\u001b[0m  \u001b[01;35mbf6c6d6d4468bf4e7526be85733decdf.jpg\u001b[0m\r\n",
      "\u001b[01;35m37a688698a6d6a34c1753b55ac876705.jpg\u001b[0m  \u001b[01;35mbf832f37e4a4fe656aedc466fb456323.jpg\u001b[0m\r\n",
      "\u001b[01;35m39b72b5383752892d260f4c9edf0a284.jpg\u001b[0m  \u001b[01;35mc10d57818ce6bcd08a648cf69e7914f2.jpg\u001b[0m\r\n",
      "\u001b[01;35m3a6618d8ee1c8a0c207e46950e53e3fc.jpg\u001b[0m  \u001b[01;35mc1f4910f015c809e6527ebab81f17acf.jpg\u001b[0m\r\n",
      "\u001b[01;35m3cf73d42c1afae0c5a8615616140d9da.jpg\u001b[0m  \u001b[01;35mc29a24a3d468b854e9b593bc4a6ce173.jpg\u001b[0m\r\n",
      "\u001b[01;35m3d0ac7238cb05f41935dff4a18435015.jpg\u001b[0m  \u001b[01;35mc2ea38afc21f50539154964fe393acbb.jpg\u001b[0m\r\n",
      "\u001b[01;35m3d535fc202523f86d91dc5b42660ef84.jpg\u001b[0m  \u001b[01;35mc6078c7dd44948b063d0dddb7968520d.jpg\u001b[0m\r\n",
      "\u001b[01;35m3e00d4cc024a68dd17a7cf3dc1deea5e.jpg\u001b[0m  \u001b[01;35mc6ca3942861280a09bd1dfc506618b64.jpg\u001b[0m\r\n",
      "\u001b[01;35m3e68e58af4b396f7d6f666a347377916.jpg\u001b[0m  \u001b[01;35mc77ee8707cd44869b3689182d9664b91.jpg\u001b[0m\r\n",
      "\u001b[01;35m3e6d6dae7ee52c1595f3abd91feeacad.jpg\u001b[0m  \u001b[01;35mcab31a0ee5e50f0999370ec0c1be00d0.jpg\u001b[0m\r\n",
      "\u001b[01;35m3ea7da5aee9a362c1c65c07dc6257c88.jpg\u001b[0m  \u001b[01;35mcad3ea6316048ecc5873061e703116b2.jpg\u001b[0m\r\n",
      "\u001b[01;35m3ee8e15976bbb4c279d81d46d87b85e7.jpg\u001b[0m  \u001b[01;35mcc133d49c27d6b1e979d4b797b43e676.jpg\u001b[0m\r\n",
      "\u001b[01;35m3f3699151e86cb4e31f3d461cdf7c06b.jpg\u001b[0m  \u001b[01;35mcceee8ec03d0ec8cc1cf8c5338a5496d.jpg\u001b[0m\r\n",
      "\u001b[01;35m3fcd831b3c679e7ab6f6f418e40f0b7b.jpg\u001b[0m  \u001b[01;35mce044ed34208e35a977a36cd8cf6136a.jpg\u001b[0m\r\n",
      "\u001b[01;35m4122d92c06fef242b531d4a8e7571631.jpg\u001b[0m  \u001b[01;35mce19e7a8e500cadd70a523ac2c7f508e.jpg\u001b[0m\r\n",
      "\u001b[01;35m4190dbe00a9dcfbd27208f9b1c956e33.jpg\u001b[0m  \u001b[01;35mce54723d69985c8c9e909f55ff59240b.jpg\u001b[0m\r\n",
      "\u001b[01;35m41e8a04c57a9f20ff6d6f954eb736a97.jpg\u001b[0m  \u001b[01;35mcf9d4c377c2482ea2857a0f9dd207993.jpg\u001b[0m\r\n",
      "\u001b[01;35m438a99bf2163df745c9303c7650beea7.jpg\u001b[0m  _classes.txt\r\n",
      "\u001b[01;35m441a567578734de915735b69ac018342.jpg\u001b[0m  coco_annotation.py\r\n",
      "\u001b[01;35m44a689c225b3cef9ce68c669e37c7478.jpg\u001b[0m  convert.py\r\n",
      "\u001b[01;35m4647d7da27a40e760e4f21ef6d5a219f.jpg\u001b[0m  \u001b[01;35md0e26d9856c5330993fd0ac06fbb348a.jpg\u001b[0m\r\n",
      "\u001b[01;35m4673f994f60a2ea7afdddc1b752947c0.jpg\u001b[0m  \u001b[01;35md1db98c2769632aa5c3b590f8dd25a01.jpg\u001b[0m\r\n",
      "\u001b[01;35m46d2ecc7004c3de4ab1180ed4d8772f8.jpg\u001b[0m  \u001b[01;35md215dd551052cb175c7433a759ce04b4.jpg\u001b[0m\r\n",
      "\u001b[01;35m471bd4e081267ec5a1f7f96e914a08e0.jpg\u001b[0m  \u001b[01;35md31891ed8c146345589264967eeb63ce.jpg\u001b[0m\r\n",
      "\u001b[01;35m4751b958e98a485f42b5bb91fadf5ef6.jpg\u001b[0m  \u001b[01;35md4371793c4a59267c64fdce04338b549.jpg\u001b[0m\r\n",
      "\u001b[01;35m47671c8812a971f5197441084ced4912.jpg\u001b[0m  \u001b[01;35md46bd0f705188dd46e38d84b1c79a23b.jpg\u001b[0m\r\n",
      "\u001b[01;35m4903df89ce9d5d1c4141ac4cfe4af12d.jpg\u001b[0m  \u001b[01;35md50a1cfaf3ff21502f27b93014f3e9c0.jpg\u001b[0m\r\n",
      "\u001b[01;35m49611b054e12fe1964af42a2a5f1293f.jpg\u001b[0m  \u001b[01;35md528791406f2caf1552084e2a2fde900.jpg\u001b[0m\r\n",
      "\u001b[01;35m49d31dc46d8f446df3bf6c72b79d4a73.jpg\u001b[0m  \u001b[01;35md58efc544cf00101e0f99d0256c45234.jpg\u001b[0m\r\n",
      "\u001b[01;35m4a0ec96e59a6ecc577f9194ddb3d860d.jpg\u001b[0m  \u001b[01;35md75c53a2a4d0b9232153b52c0d0d7ede.jpg\u001b[0m\r\n",
      "\u001b[01;35m4a615740264dd7042b5b95843ddbc88b.jpg\u001b[0m  \u001b[01;35md7674c0e7890c303967c8cccc6204375.jpg\u001b[0m\r\n",
      "\u001b[01;35m4b31840d2cc06fb1b309a76c0a12ff81.jpg\u001b[0m  \u001b[01;35md8f4662421281456582717ea45e0669f.jpg\u001b[0m\r\n",
      "\u001b[01;35m4bb19fb85ec43cb59128c4876b769b6a.jpg\u001b[0m  \u001b[01;35md93a5e6c76001207bf1ef82e4064e6d0.jpg\u001b[0m\r\n",
      "\u001b[01;35m4c5b94551e57ab04354d77c8b71ce7be.jpg\u001b[0m  \u001b[01;35mda8b427e50257c69982cddfa5431e0ba.jpg\u001b[0m\r\n",
      "\u001b[01;35m4c6101c3f30d730a4a0ac27d45401950.jpg\u001b[0m  darknet53.cfg\r\n",
      "\u001b[01;35m4c61293a1cf38b1d057ce892a5fd47c9.jpg\u001b[0m  \u001b[01;35mdc0ce38e8224d4961e9be7bdeecd7a80.jpg\u001b[0m\r\n",
      "\u001b[01;35m4cf686cb8e2cdb9178c01f040fc1b86c.jpg\u001b[0m  \u001b[01;35mdc4fea6db87e6b97b6060c788fcb38ed.jpg\u001b[0m\r\n",
      "\u001b[01;35m4d711d905ba244ac7d1d5cf6f47ab5d4.jpg\u001b[0m  \u001b[01;35mdd07c7329f95af9afd13c62523d95ce8.jpg\u001b[0m\r\n",
      "\u001b[01;35m4e1f70a737a49533a64d5b9a750591df.jpg\u001b[0m  \u001b[01;35mdeb2a655d915e2aa5bb8652977b460c3.jpg\u001b[0m\r\n",
      "\u001b[01;35m4fa05947777eb333fdf7fef7f6a39aa3.jpg\u001b[0m  \u001b[01;35mdedb7c63796710f0a598e3b7baeed76a.jpg\u001b[0m\r\n",
      "\u001b[01;35m52195ec09cfde7738f514483ab0faab5.jpg\u001b[0m  \u001b[01;35mdf7bf23db19e607646a6c424a8d39067.jpg\u001b[0m\r\n",
      "\u001b[01;35m5251a9548976dcd9e9cf377f968d5110.jpg\u001b[0m  \u001b[01;35mdfb3847dad2a3a269cad51f6e99b23fd.jpg\u001b[0m\r\n",
      "\u001b[01;35m53ad46f0d8fc0af89de3f0a4b7373daf.jpg\u001b[0m  \u001b[01;35me2ead6cef23be53d6d1e5ecd22ba90cf.jpg\u001b[0m\r\n",
      "\u001b[01;35m5537e84bf703323dea17e99fc1e46fbe.jpg\u001b[0m  \u001b[01;35me326857ff4207758d9dba05d756c6cf6.jpg\u001b[0m\r\n",
      "\u001b[01;35m5b26b81380ab1bec7867d3d102d83f74.jpg\u001b[0m  \u001b[01;35me3c49ae97c37ec7b2a05b18600efac5d.jpg\u001b[0m\r\n",
      "\u001b[01;35m5ca7f0cb1c500554e65ad031190f8e9f.jpg\u001b[0m  \u001b[01;35me43db05532253f717b6045a0fd6215b0.jpg\u001b[0m\r\n",
      "\u001b[01;35m5e3fb661f1ac554dff004359df72387e.jpg\u001b[0m  \u001b[01;35me562ee6ea0737d165b1da67624dd8987.jpg\u001b[0m\r\n",
      "\u001b[01;35m5f716918bfde18a52c093707c4921789.jpg\u001b[0m  \u001b[01;35me7c744c80cf1cfbb05487523bd31865d.jpg\u001b[0m\r\n",
      "\u001b[01;35m60aeeff2a621a8ec9cb371cd00317c2b.jpg\u001b[0m  \u001b[01;35me7c89abb4eb1fc215565e3a6ba315586.jpg\u001b[0m\r\n",
      "\u001b[01;35m61320a49499bda6bb7f321c35bb53d9d.jpg\u001b[0m  \u001b[01;35me84751775955296abea5c02e9f7f76cf.jpg\u001b[0m\r\n",
      "\u001b[01;35m615cc6dc2a47c67afb931d9a51824037.jpg\u001b[0m  \u001b[01;35me8f60c0e9e679a823c65ca13ac5fa77a.jpg\u001b[0m\r\n",
      "\u001b[01;35m62c6410f0717a807c41d40cf6b4964e1.jpg\u001b[0m  \u001b[01;35me928eeb105e859d381384d51dfba74f0.jpg\u001b[0m\r\n",
      "\u001b[01;35m65c0d23bbc6c2d77c4a0488db9abac77.jpg\u001b[0m  \u001b[01;35mec021e67720e0ac5cc75bbcf26f03945.jpg\u001b[0m\r\n",
      "\u001b[01;35m663e7be934f3039cdd089fb286908ecf.jpg\u001b[0m  \u001b[01;35mec48ef12e5c2da9192d917dd4d5c38ad.jpg\u001b[0m\r\n",
      "\u001b[01;35m6685801852e1619c3db6c5b1a89f804f.jpg\u001b[0m  \u001b[01;35mec610cade260cff00e4d5733c679c3de.jpg\u001b[0m\r\n",
      "\u001b[01;35m679cdadab56df2b7a2219c2dc991405a.jpg\u001b[0m  \u001b[01;35mece61f608b3818a78335fbb492c835b7.jpg\u001b[0m\r\n",
      "\u001b[01;35m6b2a7d11616d09ca272839f2c9e78c8d.jpg\u001b[0m  \u001b[01;35meedf2b3d9c39bba074a186368853b39f.jpg\u001b[0m\r\n",
      "\u001b[01;35m6bc9b8a32fd443dc481e721dfae8bd6a.jpg\u001b[0m  \u001b[01;35mef2520d3f775b4a6b7f756ceeafa1d5e.jpg\u001b[0m\r\n",
      "\u001b[01;35m6c3bcb67b1481fb40443deb8d694955e.jpg\u001b[0m  \u001b[01;35mef30e6c0211bb751e9df4ab3a14d894c.jpg\u001b[0m\r\n",
      "\u001b[01;35m6d7ed947bf52caa7113b4d012a1d7d75.jpg\u001b[0m  \u001b[01;35mef4ed5721285d6a77aee0c9e30e8df02.jpg\u001b[0m\r\n",
      "\u001b[01;35m6da0ea5f251340c9505b914a7ea78082.jpg\u001b[0m  \u001b[01;35mefbf0cfc24d8a91265deaa45d05af584.jpg\u001b[0m\r\n",
      "\u001b[01;35m6e021f7b2c75e65b134f1dfb4465f5df.jpg\u001b[0m  \u001b[01;34mexport\u001b[0m/\r\n",
      "\u001b[01;35m6e25b8e19ae48f3872bd5eab3d578e09.jpg\u001b[0m  \u001b[01;35mf01aaf35d0d831ef8fa0777719784c19.jpg\u001b[0m\r\n",
      "\u001b[01;35m6e331e23c51d04f0eceea1f9023f3ee9.jpg\u001b[0m  \u001b[01;35mf05a78bda48dce1977b0c908d0b7a69a.jpg\u001b[0m\r\n",
      "\u001b[01;35m7010666befa8b4202ae1f319c259fd8e.jpg\u001b[0m  \u001b[01;35mf0caf176dc8ec78aa856f2b0f46bd54e.jpg\u001b[0m\r\n",
      "\u001b[01;35m708034816396f76630b4b1813192e302.jpg\u001b[0m  \u001b[01;35mf2b132da5554bb6206f3ac543dc24614.jpg\u001b[0m\r\n",
      "\u001b[01;35m717051c1cb096a53794b246d4cf038a6.jpg\u001b[0m  \u001b[01;35mf31caa81af9764a371336852e1f5b311.jpg\u001b[0m\r\n",
      "\u001b[01;35m71ad7edd0118ef2b86663002a70d585f.jpg\u001b[0m  \u001b[01;35mf3cd7d7511cd74144f9a36f454a41938.jpg\u001b[0m\r\n",
      "\u001b[01;35m73555f112907e86bfafed44f71a148ef.jpg\u001b[0m  \u001b[01;35mf44f94809fd9d56b6d61de01e39f6564.jpg\u001b[0m\r\n",
      "\u001b[01;35m73fdd346c54e5d29fa548a7e7dbff175.jpg\u001b[0m  \u001b[01;35mf4ad57f26fb743a960adf55a3d529e8f.jpg\u001b[0m\r\n",
      "\u001b[01;35m75e29c304561ffc13a23c8f7f70a7c36.jpg\u001b[0m  \u001b[01;35mf6ef8c1299edc5a8e917b888992bda52.jpg\u001b[0m\r\n",
      "\u001b[01;35m76437ea0f0e279a6a41f194c2c2b1aa9.jpg\u001b[0m  \u001b[01;35mf7a4a57cdbca6047cdaa0276a480f37d.jpg\u001b[0m\r\n",
      "\u001b[01;35m78fbe3bd1099d0a705be5b548b1cc4c8.jpg\u001b[0m  \u001b[01;35mf8630684319e46b68de7ce8d2304a302.jpg\u001b[0m\r\n",
      "\u001b[01;35m796613514b414f81a14b3ac2f0ae4107.jpg\u001b[0m  \u001b[01;35mf8ecce66d12f2fa1ce56da09f655c701.jpg\u001b[0m\r\n",
      "\u001b[01;35m798aa55f3762983463971aec7c614d79.jpg\u001b[0m  \u001b[01;35mf91c54cdd724a292b6b3d4316ea0a7b6.jpg\u001b[0m\r\n",
      "\u001b[01;35m7995269764aa1bc8a0ae361a75ab7940.jpg\u001b[0m  \u001b[01;35mf9215ce495aad438e56ad01220045662.jpg\u001b[0m\r\n",
      "\u001b[01;35m79bb62bc2c7e539d45b85d4b4924832f.jpg\u001b[0m  \u001b[01;35mfa95f13af4a64802510d44ad67aa705c.jpg\u001b[0m\r\n",
      "\u001b[01;35m7b37d7ccc4b31387a48cc9715739e0e3.jpg\u001b[0m  \u001b[01;35mfab98107e404bec110fbec7aa04bf6a6.jpg\u001b[0m\r\n",
      "\u001b[01;35m7c62d25fd0c77f8c32bc6b781c055df3.jpg\u001b[0m  \u001b[01;35mfbe3f6991b987b1ae5be069bc5e100ed.jpg\u001b[0m\r\n",
      "\u001b[01;35m7c87d6838d146122ef94f2f78494adb2.jpg\u001b[0m  \u001b[01;35mfbf15139f38a46e02b5f4061c0c9b08f.jpg\u001b[0m\r\n",
      "\u001b[01;35m7cb1383efcf128f06b9cef3ba1ed5f7a.jpg\u001b[0m  \u001b[01;35mfd116ea829fb9c6c6604c3a7baa70357.jpg\u001b[0m\r\n",
      "\u001b[01;35m7ccd5103b5b381680536745ce01a875a.jpg\u001b[0m  \u001b[01;35mfd13f39384b64a1447956b8f48271eb5.jpg\u001b[0m\r\n",
      "\u001b[01;35m7d379742516b2c1a3f1e19fbe4bce095.jpg\u001b[0m  \u001b[01;34mfont\u001b[0m/\r\n",
      "\u001b[01;35m7ef06bd5a52cd8ca24c505b6b05703de.jpg\u001b[0m  kmeans.py\r\n",
      "\u001b[01;35m7fa17062f732a1d58470ab4adbc1f245.jpg\u001b[0m  LICENSE\r\n",
      "\u001b[01;35m804339c5f8807fe987d059bf7bc4e516.jpg\u001b[0m  \u001b[01;34mmodel_data\u001b[0m/\r\n",
      "\u001b[01;35m8124fe4c673844b230c5e5c95e8f8817.jpg\u001b[0m  README.dataset.txt\r\n",
      "\u001b[01;35m818ba349eb81aafbfbb7577d2c2dd3b5.jpg\u001b[0m  README.md\r\n",
      "\u001b[01;35m8233089e3c7267a3e39e6bcb0320e0d1.jpg\u001b[0m  README.roboflow.txt\r\n",
      "\u001b[01;35m82ac4c34d937f03cd92de0302affb393.jpg\u001b[0m  train_bottleneck.py\r\n",
      "\u001b[01;35m82e1e54400d0f2eb1ab520416dcb6e8c.jpg\u001b[0m  train.py\r\n",
      "\u001b[01;35m8424a55e4ad5bc1325f2c15414eb791b.jpg\u001b[0m  voc_annotation.py\r\n",
      "\u001b[01;35m84fc8705033f6acf0394949c550451e3.jpg\u001b[0m  \u001b[01;34myolo3\u001b[0m/\r\n",
      "\u001b[01;35m851d4c592e26de69e92118db89e4aee7.jpg\u001b[0m  yolo.py\r\n",
      "\u001b[01;35m855ae08bbb269e4663161fdd02584db6.jpg\u001b[0m  yolov3.cfg\r\n",
      "\u001b[01;35m85badd562b70c911437b896ba28bfde7.jpg\u001b[0m  yolov3-tiny.cfg\r\n",
      "\u001b[01;35m8600784f9c50989109c25cd6e5b93e0d.jpg\u001b[0m  yolo_video.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-02 23:38:27--  https://pjreddie.com/media/files/yolov3.weights\n",
      "Распознаётся pjreddie.com (pjreddie.com)… 128.208.4.108\n",
      "Подключение к pjreddie.com (pjreddie.com)|128.208.4.108|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 248007048 (237M) [application/octet-stream]\n",
      "Сохранение в: «yolov3.weights»\n",
      "\n",
      "yolov3.weights      100%[===================>] 236,52M  1,63MB/s    за 99s     \n",
      "\n",
      "2020-02-02 23:40:08 (2,39 MB/s) - «yolov3.weights» сохранён [248007048/248007048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download our DarkNet weights \n",
    "!wget https://pjreddie.com/media/files/yolov3.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"convert.py\", line 14, in <module>\r\n",
      "    from keras import backend as K\r\n",
      "ModuleNotFoundError: No module named 'keras'\r\n"
     ]
    }
   ],
   "source": [
    "# call a Python script to set up our architecture with downloaded pre-trained weights\n",
    "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые вещи будем делать через консоль, потому что командная строка здесь запускается через энв. base :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-02 23:47:18--  https://pjreddie.com/media/files/yolov3-tiny.weights\n",
      "Распознаётся pjreddie.com (pjreddie.com)… 128.208.4.108\n",
      "Подключение к pjreddie.com (pjreddie.com)|128.208.4.108|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 35434956 (34M) [application/octet-stream]\n",
      "Сохранение в: «yolov3-tiny.weights»\n",
      "\n",
      "yolov3-tiny.weights 100%[===================>]  33,79M  3,56MB/s    за 16s     \n",
      "\n",
      "2020-02-02 23:47:40 (2,07 MB/s) - «yolov3-tiny.weights» сохранён [35434956/35434956]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download our DarkNet weights \n",
    "!wget https://pjreddie.com/media/files/yolov3-tiny.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"convert.py\", line 14, in <module>\r\n",
      "    from keras import backend as K\r\n",
      "ModuleNotFoundError: No module named 'keras'\r\n"
     ]
    }
   ],
   "source": [
    "# call a Python script to set up our architecture with downloaded pre-trained weights\n",
    "!python convert.py yolov3-tiny.cfg yolov3-tiny.weights model_data/yolo.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sima/SIMA/Diploma/NN_TRAINING/keras-yolo3\n"
     ]
    }
   ],
   "source": [
    "%cd keras-yolo3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------CLASS NAMES-------------------\n",
      "['black-bishop', 'black-king', 'black-knight', 'black-pawn', 'black-queen', 'black-rook', 'white-bishop', 'white-king', 'white-knight', 'white-pawn', 'white-queen', 'white-rook']\n",
      "-------------------CLASS NAMES-------------------\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "Create YOLOv3 model with 9 anchors and 12 classes.\n",
      "Load weights model_data/yolo.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3080: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Train on 232 samples, val on 57 samples, with batch size 1.\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/500\n",
      "232/232 [==============================] - 162s 699ms/step - loss: 842.1511 - val_loss: 5761.4392\n",
      "WARNING:tensorflow:From /home/sima/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/500\n",
      "232/232 [==============================] - 157s 677ms/step - loss: 212.9939 - val_loss: 5785.3113\n",
      "Epoch 3/500\n",
      "232/232 [==============================] - 156s 673ms/step - loss: 186.2980 - val_loss: 5826.9183\n",
      "Epoch 4/500\n",
      "232/232 [==============================] - 155s 669ms/step - loss: 154.0345 - val_loss: 5902.3508\n",
      "Epoch 5/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 135.0724 - val_loss: 5921.7666\n",
      "Epoch 6/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 143.3621 - val_loss: 6008.9953\n",
      "Epoch 7/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 139.2783 - val_loss: 6073.0683\n",
      "Epoch 8/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 133.8026 - val_loss: 6139.8920\n",
      "Epoch 9/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 128.2949 - val_loss: 6161.8883\n",
      "Epoch 10/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 122.4851 - val_loss: 6138.1682\n",
      "Epoch 11/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 119.1283 - val_loss: 6128.7903\n",
      "Epoch 12/500\n",
      "232/232 [==============================] - 152s 657ms/step - loss: 121.9369 - val_loss: 6123.3523\n",
      "Epoch 13/500\n",
      "232/232 [==============================] - 153s 661ms/step - loss: 119.9283 - val_loss: 6134.8260\n",
      "Epoch 14/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 120.5573 - val_loss: 6062.2157\n",
      "Epoch 15/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 122.1130 - val_loss: 6096.4052\n",
      "Epoch 16/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 120.0723 - val_loss: 6073.7782\n",
      "Epoch 17/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 115.6671 - val_loss: 6032.7707\n",
      "Epoch 18/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 117.1614 - val_loss: 6078.8625\n",
      "Epoch 19/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 116.0715 - val_loss: 6084.7287\n",
      "Epoch 20/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 119.3826 - val_loss: 6028.6750\n",
      "Epoch 21/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 114.7043 - val_loss: 5976.0359\n",
      "Epoch 22/500\n",
      "232/232 [==============================] - 153s 657ms/step - loss: 113.6099 - val_loss: 5979.3284\n",
      "Epoch 23/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 115.0659 - val_loss: 5886.2640\n",
      "Epoch 24/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 114.6512 - val_loss: 5826.1625\n",
      "Epoch 25/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 115.1021 - val_loss: 5802.1426\n",
      "Epoch 26/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 115.1958 - val_loss: 5843.7226\n",
      "Epoch 27/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 111.9177 - val_loss: 5703.3732\n",
      "Epoch 28/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 115.3129 - val_loss: 5747.1062\n",
      "Epoch 29/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 115.2859 - val_loss: 5599.1332\n",
      "Epoch 30/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 113.4935 - val_loss: 5521.5455\n",
      "Epoch 31/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 113.9060 - val_loss: 5383.3994\n",
      "Epoch 32/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.4832 - val_loss: 5426.2887\n",
      "Epoch 33/500\n",
      "232/232 [==============================] - 152s 655ms/step - loss: 112.9652 - val_loss: 5353.3101\n",
      "Epoch 34/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 111.9059 - val_loss: 5228.6290\n",
      "Epoch 35/500\n",
      "202/232 [=========================>....] - ETA: 15s - loss: 111.0230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 153s 658ms/step - loss: 112.2028 - val_loss: 3781.9896\n",
      "Epoch 55/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 111.2834 - val_loss: 3724.3358\n",
      "Epoch 56/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.8559 - val_loss: 3718.8456\n",
      "Epoch 57/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.8887 - val_loss: 3645.3622\n",
      "Epoch 58/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 110.7277 - val_loss: 3593.4762\n",
      "Epoch 59/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.3257 - val_loss: 3539.2100\n",
      "Epoch 60/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.6652 - val_loss: 3462.0915\n",
      "Epoch 61/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.2735 - val_loss: 3412.2850\n",
      "Epoch 62/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.2621 - val_loss: 3393.1481\n",
      "Epoch 63/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 111.1744 - val_loss: 3324.7320\n",
      "Epoch 64/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 111.3648 - val_loss: 3311.8919\n",
      "Epoch 65/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 111.4212 - val_loss: 3222.3800\n",
      "Epoch 66/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 112.5347 - val_loss: 3164.2570\n",
      "Epoch 67/500\n",
      "181/232 [======================>.......] - ETA: 26s - loss: 104.6577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 152s 657ms/step - loss: 111.6306 - val_loss: 2231.5432\n",
      "Epoch 89/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.5818 - val_loss: 2185.8348\n",
      "Epoch 90/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 109.3907 - val_loss: 2165.8194\n",
      "Epoch 91/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 112.1673 - val_loss: 2124.3623\n",
      "Epoch 92/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 110.6017 - val_loss: 2086.5620\n",
      "Epoch 93/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 111.4153 - val_loss: 2048.9513\n",
      "Epoch 94/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 107.9013 - val_loss: 1999.5822\n",
      "Epoch 95/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 109.1475 - val_loss: 1993.7560\n",
      "Epoch 96/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 112.2252 - val_loss: 1911.1058\n",
      "Epoch 97/500\n",
      "232/232 [==============================] - 153s 659ms/step - loss: 110.4586 - val_loss: 1916.9165\n",
      "Epoch 98/500\n",
      "232/232 [==============================] - 153s 658ms/step - loss: 109.0817 - val_loss: 1926.1975\n",
      "Epoch 99/500\n",
      "232/232 [==============================] - 152s 656ms/step - loss: 110.5599 - val_loss: 1887.4016\n",
      "Epoch 100/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 110.1965 - val_loss: 1883.8496\n",
      "Epoch 101/500\n",
      "  4/232 [..............................] - ETA: 1:58 - loss: 95.9535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 653ms/step - loss: 110.7167 - val_loss: 1442.6111\n",
      "Epoch 121/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 110.3539 - val_loss: 1433.8467\n",
      "Epoch 122/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 110.8796 - val_loss: 1442.4760\n",
      "Epoch 123/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 110.6417 - val_loss: 1370.7744\n",
      "Epoch 124/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 111.6499 - val_loss: 1365.3138\n",
      "Epoch 125/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 110.7479 - val_loss: 1353.1911\n",
      "Epoch 126/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 109.5141 - val_loss: 1342.7984\n",
      "Epoch 127/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 109.7437 - val_loss: 1299.7086\n",
      "Epoch 128/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 111.2687 - val_loss: 1294.3757\n",
      "Epoch 129/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 110.5317 - val_loss: 1290.3767\n",
      "Epoch 130/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 110.4862 - val_loss: 1252.7702\n",
      "Epoch 131/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 110.2155 - val_loss: 1281.6874\n",
      "Epoch 132/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.8822 - val_loss: 1226.2017\n",
      "Epoch 133/500\n",
      "101/232 [============>.................] - ETA: 1:08 - loss: 106.8033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 652ms/step - loss: 106.2034 - val_loss: 1048.9177\n",
      "Epoch 153/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 109.4929 - val_loss: 1019.1192\n",
      "Epoch 154/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 110.1217 - val_loss: 978.7604\n",
      "Epoch 155/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 111.0371 - val_loss: 974.3732\n",
      "Epoch 156/500\n",
      "232/232 [==============================] - 151s 651ms/step - loss: 109.8013 - val_loss: 953.4989\n",
      "Epoch 157/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.7608 - val_loss: 952.9639\n",
      "Epoch 158/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 109.2575 - val_loss: 975.9495\n",
      "Epoch 159/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.8706 - val_loss: 948.0966\n",
      "Epoch 160/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.2023 - val_loss: 949.7384\n",
      "Epoch 161/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 111.1657 - val_loss: 922.0928\n",
      "Epoch 162/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.1567 - val_loss: 921.4238\n",
      "Epoch 163/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.6506 - val_loss: 888.7560\n",
      "Epoch 164/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 110.3868 - val_loss: 903.0367\n",
      "Epoch 165/500\n",
      "134/232 [================>.............] - ETA: 51s - loss: 98.6725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 653ms/step - loss: 109.8121 - val_loss: 726.0923\n",
      "Epoch 187/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.7346 - val_loss: 711.9068\n",
      "Epoch 188/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.9988 - val_loss: 708.2568\n",
      "Epoch 189/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 107.8878 - val_loss: 692.8551\n",
      "Epoch 190/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 107.1806 - val_loss: 693.1912\n",
      "Epoch 191/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.5366 - val_loss: 675.6770\n",
      "Epoch 192/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 109.4392 - val_loss: 698.7317\n",
      "Epoch 193/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.8413 - val_loss: 701.1454\n",
      "Epoch 194/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.8244 - val_loss: 697.8983\n",
      "Epoch 195/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 109.3696 - val_loss: 691.7479\n",
      "Epoch 196/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 109.3704 - val_loss: 667.7879\n",
      "Epoch 197/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.5443 - val_loss: 679.5760\n",
      "Epoch 198/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 109.2381 - val_loss: 659.5455\n",
      "Epoch 199/500\n",
      " 59/232 [======>.......................] - ETA: 1:30 - loss: 95.5443"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 652ms/step - loss: 108.2444 - val_loss: 570.0387\n",
      "Epoch 220/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.3487 - val_loss: 548.5043\n",
      "Epoch 221/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 109.5761 - val_loss: 553.3326\n",
      "Epoch 222/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.3055 - val_loss: 539.9269\n",
      "Epoch 223/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.4833 - val_loss: 539.8989\n",
      "Epoch 224/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.5374 - val_loss: 529.0781\n",
      "Epoch 225/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 110.0626 - val_loss: 540.8928\n",
      "Epoch 226/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 108.8487 - val_loss: 513.8646\n",
      "Epoch 227/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.7896 - val_loss: 515.6083\n",
      "Epoch 228/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 107.3045 - val_loss: 522.9192\n",
      "Epoch 229/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.7487 - val_loss: 497.4594\n",
      "Epoch 230/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 109.7807 - val_loss: 535.6335\n",
      "Epoch 231/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.8258 - val_loss: 528.7159\n",
      "Epoch 232/500\n",
      "160/232 [===================>..........] - ETA: 37s - loss: 102.8969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 652ms/step - loss: 107.4743 - val_loss: 453.6794\n",
      "Epoch 253/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.8017 - val_loss: 465.4451\n",
      "Epoch 254/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.5839 - val_loss: 449.9158\n",
      "Epoch 255/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 110.1668 - val_loss: 450.5820\n",
      "Epoch 256/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.8570 - val_loss: 455.0567\n",
      "Epoch 257/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 105.0405 - val_loss: 435.7191\n",
      "Epoch 258/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.6084 - val_loss: 441.6275\n",
      "Epoch 259/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.1469 - val_loss: 430.9019\n",
      "Epoch 260/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.0143 - val_loss: 429.8962\n",
      "Epoch 261/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 107.4958 - val_loss: 421.8862\n",
      "Epoch 262/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.2737 - val_loss: 421.2364\n",
      "Epoch 263/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.3969 - val_loss: 426.3461\n",
      "Epoch 264/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.0159 - val_loss: 430.7958\n",
      "Epoch 265/500\n",
      "192/232 [=======================>......] - ETA: 20s - loss: 108.7549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 652ms/step - loss: 108.7753 - val_loss: 385.9822\n",
      "Epoch 286/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.3861 - val_loss: 369.5879\n",
      "Epoch 287/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.8101 - val_loss: 370.4539\n",
      "Epoch 288/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 106.5979 - val_loss: 372.6187\n",
      "Epoch 289/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.0838 - val_loss: 372.9431\n",
      "Epoch 290/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.5785 - val_loss: 387.9486\n",
      "Epoch 291/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.8428 - val_loss: 360.1272\n",
      "Epoch 292/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 109.1360 - val_loss: 360.1895\n",
      "Epoch 293/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.3887 - val_loss: 354.3658\n",
      "Epoch 294/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.8867 - val_loss: 358.0647\n",
      "Epoch 295/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.4174 - val_loss: 376.6207\n",
      "Epoch 296/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.5451 - val_loss: 358.6685\n",
      "Epoch 297/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.2678 - val_loss: 351.5374\n",
      "Epoch 298/500\n",
      "198/232 [========================>.....] - ETA: 17s - loss: 107.1659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 152s 653ms/step - loss: 108.5466 - val_loss: 319.8078\n",
      "Epoch 320/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 104.7089 - val_loss: 322.2464\n",
      "Epoch 321/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.7678 - val_loss: 321.3566\n",
      "Epoch 322/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.9995 - val_loss: 316.6749\n",
      "Epoch 323/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 107.4245 - val_loss: 316.9903\n",
      "Epoch 324/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 107.3973 - val_loss: 307.0098\n",
      "Epoch 325/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.2783 - val_loss: 302.2141\n",
      "Epoch 326/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.0355 - val_loss: 300.1404\n",
      "Epoch 327/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 106.4164 - val_loss: 326.0458\n",
      "Epoch 328/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.6784 - val_loss: 319.5536\n",
      "Epoch 329/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 108.9852 - val_loss: 313.8930\n",
      "Epoch 330/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 109.1814 - val_loss: 307.6645\n",
      "Epoch 331/500\n",
      "231/232 [============================>.] - ETA: 0s - loss: 108.9243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 152s 653ms/step - loss: 107.7941 - val_loss: 298.3886\n",
      "Epoch 351/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.2327 - val_loss: 293.0004\n",
      "Epoch 352/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.5328 - val_loss: 282.6950\n",
      "Epoch 353/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 109.1317 - val_loss: 275.1437\n",
      "Epoch 354/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.3427 - val_loss: 281.3652\n",
      "Epoch 355/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.4048 - val_loss: 286.4539\n",
      "Epoch 356/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.6687 - val_loss: 281.5615\n",
      "Epoch 357/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.2164 - val_loss: 276.7134\n",
      "Epoch 358/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.8677 - val_loss: 272.9113\n",
      "Epoch 359/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.8112 - val_loss: 277.5115\n",
      "Epoch 360/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 105.4500 - val_loss: 273.2609\n",
      "Epoch 361/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.4068 - val_loss: 270.8556\n",
      "Epoch 362/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.2142 - val_loss: 281.1026\n",
      "Epoch 363/500\n",
      "105/232 [============>.................] - ETA: 1:06 - loss: 110.1476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 653ms/step - loss: 106.2054 - val_loss: 255.3807\n",
      "Epoch 384/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 104.9204 - val_loss: 255.7127\n",
      "Epoch 385/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 110.3758 - val_loss: 240.8218\n",
      "Epoch 386/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.1282 - val_loss: 248.5549\n",
      "Epoch 387/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.0088 - val_loss: 249.4866\n",
      "Epoch 388/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.6507 - val_loss: 253.1290\n",
      "Epoch 389/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.9653 - val_loss: 255.5539\n",
      "Epoch 390/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 104.7120 - val_loss: 249.7358\n",
      "Epoch 391/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 106.3981 - val_loss: 254.4204\n",
      "Epoch 392/500\n",
      "232/232 [==============================] - 152s 655ms/step - loss: 107.2342 - val_loss: 242.6322\n",
      "Epoch 393/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.4403 - val_loss: 242.6398\n",
      "Epoch 394/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.1152 - val_loss: 242.9844\n",
      "Epoch 395/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.5806 - val_loss: 243.3889\n",
      "Epoch 396/500\n",
      " 54/232 [=====>........................] - ETA: 1:32 - loss: 97.2675"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 653ms/step - loss: 108.0642 - val_loss: 225.2486\n",
      "Epoch 417/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 109.2191 - val_loss: 230.7105\n",
      "Epoch 418/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.2504 - val_loss: 223.1450\n",
      "Epoch 419/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.4373 - val_loss: 232.8278\n",
      "Epoch 420/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 106.2536 - val_loss: 228.5819\n",
      "Epoch 421/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.7777 - val_loss: 220.8041\n",
      "Epoch 422/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.7294 - val_loss: 227.4774\n",
      "Epoch 423/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 107.4362 - val_loss: 226.4967\n",
      "Epoch 424/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 107.0512 - val_loss: 230.1296\n",
      "Epoch 425/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.7476 - val_loss: 227.7847\n",
      "Epoch 426/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 104.4696 - val_loss: 225.7493\n",
      "Epoch 427/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 106.2061 - val_loss: 221.0848\n",
      "Epoch 428/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 109.8340 - val_loss: 221.3528\n",
      "Epoch 429/500\n",
      "134/232 [================>.............] - ETA: 51s - loss: 111.4734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 652ms/step - loss: 105.6469 - val_loss: 211.8499\n",
      "Epoch 451/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.6259 - val_loss: 206.8693\n",
      "Epoch 452/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.3317 - val_loss: 208.6959\n",
      "Epoch 453/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 106.1517 - val_loss: 214.1546\n",
      "Epoch 454/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 106.6411 - val_loss: 205.4938\n",
      "Epoch 455/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 106.5619 - val_loss: 205.2274\n",
      "Epoch 456/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 110.0728 - val_loss: 216.9538\n",
      "Epoch 457/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 110.0030 - val_loss: 213.7103\n",
      "Epoch 458/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 106.9831 - val_loss: 214.2392\n",
      "Epoch 459/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.9598 - val_loss: 216.0023\n",
      "Epoch 460/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.7962 - val_loss: 214.8893\n",
      "Epoch 461/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.6342 - val_loss: 212.7272\n",
      "Epoch 462/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 106.2345 - val_loss: 212.3437\n",
      "Epoch 463/500\n",
      "108/232 [============>.................] - ETA: 1:04 - loss: 113.5277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 151s 652ms/step - loss: 106.9155 - val_loss: 199.0201\n",
      "Epoch 482/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.3161 - val_loss: 206.3990\n",
      "Epoch 483/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.1867 - val_loss: 200.0123\n",
      "Epoch 484/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 107.0322 - val_loss: 196.3877\n",
      "Epoch 485/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.9941 - val_loss: 199.5387\n",
      "Epoch 486/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.5777 - val_loss: 201.0429\n",
      "Epoch 487/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 108.7632 - val_loss: 206.8298\n",
      "Epoch 488/500\n",
      "232/232 [==============================] - 151s 650ms/step - loss: 106.6660 - val_loss: 203.7341\n",
      "Epoch 489/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 108.6393 - val_loss: 202.4740\n",
      "Epoch 490/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 106.9171 - val_loss: 201.0320\n",
      "Epoch 491/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.0725 - val_loss: 201.7159\n",
      "Epoch 492/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 108.7812 - val_loss: 185.8637\n",
      "Epoch 493/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 109.7071 - val_loss: 194.6012\n",
      "Epoch 494/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 107.9818 - val_loss: 193.1843\n",
      "Epoch 495/500\n",
      "232/232 [==============================] - 152s 653ms/step - loss: 110.3816 - val_loss: 193.8674\n",
      "Epoch 496/500\n",
      "232/232 [==============================] - 151s 652ms/step - loss: 108.1594 - val_loss: 193.9982\n",
      "Epoch 497/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 107.2066 - val_loss: 198.8589\n",
      "Epoch 498/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.9326 - val_loss: 194.0879\n",
      "Epoch 499/500\n",
      "232/232 [==============================] - 152s 654ms/step - loss: 106.6536 - val_loss: 198.3549\n",
      "Epoch 500/500\n",
      "232/232 [==============================] - 151s 653ms/step - loss: 106.9274 - val_loss: 193.8944\n",
      "Unfreeze all of the layers.\n",
      "Train on 232 samples, val on 57 samples, with batch size 1.\n",
      "Epoch 51/100\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Self-contained Python script to train YOLOv3 on your own dataset\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "def _main():\n",
    "    annotation_path = '_annotations.txt'  # path to Roboflow data annotations\n",
    "    log_dir = 'logs/000/'                 # where we're storing our logs\n",
    "    classes_path = '_classes.txt'         # path to Roboflow class names\n",
    "    anchors_path = 'model_data/yolo_anchors.txt'\n",
    "    class_names = get_classes(classes_path)\n",
    "    print(\"-------------------CLASS NAMES-------------------\")\n",
    "    print(class_names)\n",
    "    print(\"-------------------CLASS NAMES-------------------\")\n",
    "    num_classes = len(class_names)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "\n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        print(\"________________________IS TINY VERSION_________________________\")\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
    "    else:\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model_data/yolo.h5') # make sure you know what you freeze\n",
    "\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "    val_split = 0.2 # set the size of the validation set\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "\n",
    "    # Train with frozen layers first, to get a stable loss.\n",
    "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "    if True:\n",
    "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "        batch_size = BATCH_SIZE\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=500,\n",
    "                initial_epoch=0,\n",
    "                callbacks=[logging, checkpoint])\n",
    "        model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = BATCH_SIZE # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=100,\n",
    "            initial_epoch=50,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "    # Further training if needed.\n",
    "\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    ###\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    keras.backend.tensorflow_backend.set_session(sess)\n",
    "    ###\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "#     y_true = [Input(shape=(h//{0:BATCH_SIZE, 1:16, 2:8}[l], w//{0:BATCH_SIZE, 1:16, 2:8}[l], \\\n",
    "#         num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    ###\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    keras.backend.tensorflow_backend.set_session(sess)\n",
    "    ###\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "#     y_true = [Input(shape=(h//{0:BATCH_SIZE, 1:16}[l], w//{0:BATCH_SIZE, 1:16}[l], \\\n",
    "#         num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    _main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дальше inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"yolo_video.py\", line 3, in <module>\r\n",
      "    from yolo import YOLO, detect_video\r\n",
      "  File \"/home/sima/SIMA/Diploma/NN_TRAINING/keras-yolo3/yolo.py\", line 11, in <module>\r\n",
      "    from keras import backend as K\r\n",
      "ModuleNotFoundError: No module named 'keras'\r\n"
     ]
    }
   ],
   "source": [
    "!python yolo_video.py --model=\"./logs/000/trained_weights_stage_1.h5\" --classes=\"_classes.txt\" --image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
